#!/usr/bin/env python3

import pyrealsense2 as rs
import rclpy
from rclpy.node import Node
from kobuki_ros_interfaces.msg import *
from std_msgs.msg import String
from sensor_msgs.msg import Image
from tf2_ros import *
from tf2_geometry_msgs import *
import numpy as np
import cv2,time, math
from cv_bridge import CvBridge

import matplotlib.pyplot as plt

def infiniteTalk():
    # Initialize ROS node with ROS client
    rclpy.init()
    aNode = Node('vision')
    control = Vision(aNode)
    # Start infinite loop
    rclpy.spin_once(aNode)
    # Clean everything and switch the light off
    aNode.destroy_node()
    rclpy.shutdown()
    

class Vision:
    def __init__(self, rosNode):

        self.rosNode = rosNode

        self.sound_publisher= rosNode.create_publisher(Sound, '/commands/sound', 10 )
        self.image_publisher = rosNode.create_publisher(Image, '/sensor_msgs/image', 10 )
        self.distance_publisher = rosNode.create_publisher(Pose, 'distance', 10 )
        self._timer = rosNode.create_timer(0.1, self.vision_callback)

        # Configure depth and color streams
        self.pipeline = rs.pipeline()
        self.config = rs.config()
        self.colorizer = rs.colorizer()

        # Create bridge
        self.bridge=CvBridge()

        self.config.enable_stream(rs.stream.color, 848, 480, rs.format.bgr8, 30)
        self.config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 30)

        # Start streaming
        self.pipeline.start(self.config)

        self.align_to = rs.stream.color
        self.align = rs.align(self.align_to)

        self.color_info=(0, 0, 255)
        self.rayon=10

        self.count=1
        self.refTime= time.process_time()
        self.freq= 60

        rosNode.declare_parameter( 'color', 0 )
        rosNode.declare_parameter( 'range_color', 0 )

        self.color = self.rosNode.get_parameter( 'color' ).value
        self.range_color = self.rosNode.get_parameter( 'range_color' ).value

        self.color = 65
        self.range_color = 15
        self.lo=np.array([self.color-self.range_color, 0, 0])
        self.hi=np.array([self.color+self.range_color, 255, 255])

        self.color_info=(0, 0, 255)

        self.kernel = np.ones((5, 5), np.uint8)

        self.detected = False
        self.previous_detected = False
        self.number_detected = 0
    
    def __del__(self):
        self.pipeline.stop()

    def vision_callback(self):
        # self.color = self.rosNode.get_parameter( 'color' ).value
        # self.range_color = self.rosNode.get_parameter( 'range_color' ).value

        self.lo=np.array([self.color-self.range_color, 50, 50])
        self.hi=np.array([self.color+self.range_color, 255, 255])
        while True:
            # This call waits until a new coherent set of frames is available on a device
            frames = self.pipeline.wait_for_frames()

            #Aligning color frame to depth frame
            aligned_frames =  self.align.process(frames)
            depth_frame = aligned_frames.get_depth_frame()
            frame = aligned_frames.get_color_frame()

            if not depth_frame or not frame: continue

            # Two ways to colorized the depth map
            # first : using colorizer of pyrealsense                
            colorized_depth = self.colorizer.colorize(depth_frame)
            depth_colormap = np.asanyarray(colorized_depth.get_data())

            # Get the intrinsic parameters
            color_intrin = frame.profile.as_video_stream_profile().intrinsics

            color_image_bgr = np.asanyarray(frame.get_data())
            color_image = cv2.cvtColor(color_image_bgr, cv2.COLOR_BGR2HSV)

            normalized_image = cv2.normalize(color_image, None, 0, 255, cv2.NORM_MINMAX)
            image = cv2.cvtColor(normalized_image, cv2.COLOR_HSV2BGR)

            depth_colormap_dim = depth_colormap.shape
            color_colormap_dim = color_image.shape

            mask=cv2.inRange(color_image, self.lo, self.hi)
            mask=cv2.erode(mask, self.kernel, iterations=1)
            mask=cv2.dilate(mask, self.kernel, iterations=4)
            mask=cv2.medianBlur(mask, 5)
            
            coords = []

            # Trouver les contours du masque
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            for i in range(len(contours)):
                # Obtenir le rectangle englobant (bounding box)
                c_x, c_y, c_w, c_h = cv2.boundingRect(contours[i])

                if (c_w/c_h) > 0.65 and c_w > 25 and c_h > 25:
                    # Extraire la ROI
                    roi = color_image_bgr[c_y:c_y+c_h, c_x:c_x+c_w]

                    roi_resized = cv2.resize(roi, None, fx = 100/c_w, fy = 100/c_w)
                    coords.append((c_x, c_y, c_w, c_h))
                    cv2.rectangle(color_image_bgr, (c_x, c_y), (c_x + c_w, c_y + c_h), (0,0,255), 2)
                    cv2.circle(color_image_bgr, (int(c_x + c_w/2), int(c_y + c_h/2)), 5, (0, 0, 255), 2)

                    # Afficher la ROI
                    cv2.imshow('Region d\'interet', roi_resized)
            
            self.detected = False

            for i in range(len(coords)):
                x, y, w, h = coords[i]

                if int(x + w/2) < 848 and int(y + h/2) < 480:
                    depth = depth_frame.get_distance(int(x + w/2), int(y + h/2))
                    dx ,dy, dz = rs.rs2_deproject_pixel_to_point(color_intrin, [x,y], depth)
                else:
                    dx, dy, dz = 0, 0, 0

                a = 424/(35*3.14159/180)
                theta = -(int(x + w/2) - 424)/a
                distance = math.sqrt(((dx)**2) + ((dy)**2) + ((dz)**2))
                pose = Pose()
                if distance**2<0.04:
                    pose.position.x = (float)(0)
                else:
                    pose.position.x = (float)((distance**2 - 0.04)**0.5)
                pose.position.y = (float)(distance*math.sin(theta))
                pose.position.z = (float)(0.0)
                
                if distance>=0.04:
                    self.detected = True

            if not self.detected:
                self.number_detected = 0
            if self.detected and self.previous_detected:
                self.number_detected += 1
            if self.number_detected == 30:
                sound = Sound()
                sound.value = 0
                self.sound_publisher.publish(sound)
                self.distance_publisher.publish(pose)
            
            cv2.imshow('camera',color_image_bgr)
            cv2.imshow('mask',mask)

            image2=cv2.bitwise_and(color_image_bgr, color_image_bgr, mask= mask)
            cv2.putText(color_image_bgr, "Couleur: {:d}".format(self.color), (10, 30), cv2.FONT_HERSHEY_DUPLEX, 1, self.color_info, 1, cv2.LINE_AA)

            msg_image = self.bridge.cv2_to_imgmsg(color_image_bgr,"bgr8")
            msg_image.header.stamp = self.rosNode.get_clock().now().to_msg()
            msg_image.header.frame_id = "image"
            self.image_publisher.publish(msg_image)

            if cv2.waitKey(1)&0xFF==ord('q'):
                break

            # Frequency:
            if self.count == 10 :
                newTime= time.process_time()
                self.freq= 10/((newTime-self.refTime))
                self.refTime= newTime
                self.count= 0
            self.count+= 1

            self.previous_detected = self.detected

def euclidean_distance(a, b):
    return ((a[0]-b[0])**2+(a[1]-b[1])**2)**0.5

# Execute the function.
if __name__ == "__main__":
    infiniteTalk()
